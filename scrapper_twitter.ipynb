{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API credentials\n",
    "consumer_key = \"BmvoUUcOUXhPxRR8uRC2TgKoW\"\n",
    "consumer_secret = \"bNV6inRgeUSSVerytnnnTPveW8iM9GM0dwryZyiUKmYy436D1I\"\n",
    "access_key = \"2969993776-b9Ui7fVJjW7gYId2C0kSGo5mN4ki93HSGEn6jx0\"\n",
    "access_secret = \"N5ER33zjeIqfl5918MWTHLWbZzuBGfGL0FeSfNGvSsrvZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "OAUTH_KEYS = {'consumer_key':consumer_key, 'consumer_secret':consumer_secret, 'access_token_key':access_key, 'access_token_secret':access_secret}\n",
    "auth = tweepy.OAuthHandler(OAUTH_KEYS['consumer_key'], OAUTH_KEYS['consumer_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of tweets scraped for the time window \n",
    "#(None: all, in theory, but when I tried, the limit is still 10000 ...)\n",
    "n_items_default = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_retweeted(text):\n",
    "    return text[:2] == 'RT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_retweeted(tweet):\n",
    "    try:\n",
    "        RT_info = tweet.split(':')[0]\n",
    "        if '@' in RT_info:\n",
    "            user_RT = RT_info.split()[-1]\n",
    "            user_RT = user_RT.replace('@','')\n",
    "            return user_RT\n",
    "        else:\n",
    "            return False\n",
    "        pass\n",
    "    except IndexError as ve:\n",
    "        print(tweet)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(since_date, until_date, n_items=10000):\n",
    "    cursor = tweepy.Cursor(api.search, q='#confinement',\n",
    "                           geocode=\"48.85717,2.34293,10km\",\n",
    "                           since=since_date,\n",
    "                           until=until_date).items(n_items)\n",
    "    tweet_list = []\n",
    "    while True:\n",
    "        try:\n",
    "            tweet = cursor.next()\n",
    "            tweet_list.append(tweet)\n",
    "        except tweepy.TweepError:\n",
    "            time.sleep(60 * 15)\n",
    "            continue\n",
    "        except StopIteration:\n",
    "            break\n",
    "    print('Number of tweets scrapped: ', len(tweet_list))\n",
    "\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_to_df(tweet_list):\n",
    "    \n",
    "    usernames = []\n",
    "    text = []\n",
    "    timestamp = []\n",
    "    count_rt = []\n",
    "    for tweet in tweet_list:\n",
    "        timestamp.append(tweet.created_at)\n",
    "        usernames.append(tweet.user.screen_name)\n",
    "        text.append(tweet.text)\n",
    "        count_rt.append(tweet.retweet_count)\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    df['timestamp'] = pd.to_datetime(timestamp)\n",
    "    max_date = max(df.timestamp)\n",
    "    min_date = min(df.timestamp)\n",
    "    df['username'] = usernames\n",
    "    df['count_rt'] = count_rt\n",
    "    df['text'] = text\n",
    "    df['is_retweeted'] = df.text.apply(is_retweeted)\n",
    "    df['user_retweeted'] = df.text.apply(user_retweeted)\n",
    "    df_name = 'data_confinement_' + date_until +'.csv'\n",
    "    df.to_csv(df_name)\n",
    "    print('Finished from ', min_date, ' to ', max_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31',\n",
    "        '2020-04-01', '2020-04-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With only 10 000 items per time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dates=dates, n_items=n_items_default):\n",
    "    print('Dates that will generates windows ')\n",
    "    print(dates)\n",
    "    print(n_items_default)\n",
    "    for i in range(len(dates) - 1):\n",
    "        print()\n",
    "        t1 = time.time()\n",
    "        tweet_list = scraping(dates[i], dates[i+1], n_items=n_items_default)\n",
    "        df = scrap_to_df(tweet_list)\n",
    "        csv_name = 'data_'+ str(dates[i]) + '_' + str(dates[i+1]) + '.csv'\n",
    "        t2 = time.time()\n",
    "        delta_t = t2-t1\n",
    "        print('Time taken (sec):', delta_t)\n",
    "        print('Name of saved csv file: ', csv_name)\n",
    "        print('Shape of the dataframe: ', df.shape)\n",
    "        df.to_csv(csv_name,index = False, encoding='utf-8')\n",
    "        print()\n",
    "    return 'finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates that will generates windows \n",
      "['2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02']\n",
      "10\n",
      "\n",
      "Number of tweets scrapped:  10\n",
      "Finished from  2020-03-27 23:58:33  to  2020-03-27 23:59:47\n",
      "Time taken (sec): 1.1226317882537842\n",
      "Name of saved csv file:  data_2020-03-27_2020-03-28.csv\n",
      "Shape of the dataframe:  (10, 6)\n",
      "\n",
      "\n",
      "Number of tweets scrapped:  10\n",
      "Finished from  2020-03-28 23:56:22  to  2020-03-28 23:59:40\n",
      "Time taken (sec): 0.7400047779083252\n",
      "Name of saved csv file:  data_2020-03-28_2020-03-29.csv\n",
      "Shape of the dataframe:  (10, 6)\n",
      "\n",
      "\n",
      "Number of tweets scrapped:  10\n",
      "Finished from  2020-03-29 23:53:12  to  2020-03-29 23:59:48\n",
      "Time taken (sec): 0.7577269077301025\n",
      "Name of saved csv file:  data_2020-03-29_2020-03-30.csv\n",
      "Shape of the dataframe:  (10, 6)\n",
      "\n",
      "\n",
      "Number of tweets scrapped:  10\n",
      "Finished from  2020-03-30 23:56:29  to  2020-03-30 23:59:23\n",
      "Time taken (sec): 0.6356260776519775\n",
      "Name of saved csv file:  data_2020-03-30_2020-03-31.csv\n",
      "Shape of the dataframe:  (10, 6)\n",
      "\n",
      "\n",
      "Number of tweets scrapped:  10\n",
      "Finished from  2020-03-31 23:54:49  to  2020-03-31 23:59:53\n",
      "Time taken (sec): 0.5667812824249268\n",
      "Name of saved csv file:  data_2020-03-31_2020-04-01.csv\n",
      "Shape of the dataframe:  (10, 6)\n",
      "\n",
      "\n",
      "Number of tweets scrapped:  10\n",
      "Finished from  2020-04-01 23:50:58  to  2020-04-01 23:59:27\n",
      "Time taken (sec): 0.5639870166778564\n",
      "Name of saved csv file:  data_2020-04-01_2020-04-02.csv\n",
      "Shape of the dataframe:  (10, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
